{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets # CIFAR10, MNIST\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class XORDataset(Dataset):\n",
    "    \"\"\"XOR dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, num_samples, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.num_samples = num_samples\n",
    "        self.X = np.random.randint(0,high=2, size=num_samples*2).reshape((num_samples, 2))\n",
    "        self.y = np.logical_xor(self.X[:,0], self.X[:,1]).astype(np.uint)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = {'X': self.X[idx], 'y': self.y[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X = np.random.randint(0,high=2, size=10*2).reshape((10, 2))\n",
    "y = np.logical_xor(X[:,0], X[:,1]).astype(np.uint)\n",
    "print(X)\n",
    "print(y)\n",
    "print(X[2])\n",
    "print(y[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "[1 1 0 1 0 0 1 0 0 1]\n",
      "[0 0]\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class XORnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(XORnet, self).__init__()\n",
    "        self.linear = nn.Linear(2, 2)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "        self.layers = nn.Sequential(\n",
    "            self.linear, \n",
    "            self.Sigmoid, \n",
    "            self.linear2\n",
    "        )\n",
    "        # custom weight initialization\n",
    "        nnLinearLayers = [layer for layer in self.layers if type(layer) == nn.Linear]\n",
    "        for layer in nnLinearLayers:\n",
    "            nn.init.normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "loss_fn = nn.MSELoss() \n",
    "\n",
    "model = XORnet()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs=10\n",
    "\n",
    "for epoch in range(1, epochs+1): ## run the model for 11 epochs\n",
    "    train_loss, valid_loss = [], []\n",
    "    ## training part \n",
    "    ##--------------\n",
    "    model.train()\n",
    "    for data, target in loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    ## evaluation part\n",
    "    ## ---------------\n",
    "\n",
    "    with torch.no_grad():  #gradients should not evaluate\n",
    "        model.eval()\n",
    "        for data, target in loaders['valid']:\n",
    "            output = model(data)\n",
    "            loss = lossFunction(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}